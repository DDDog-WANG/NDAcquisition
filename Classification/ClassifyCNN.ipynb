{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの分布\n",
    "\n",
    "## >> Cells With Mask\n",
    "* NDAcquisition-01：45,723\n",
    "* NDAcquisition-01x40：130,092\n",
    "* NDAcquisition-02Nami_x20：9,096\n",
    "* NDAcquisition-02Nami_x40：4,236\n",
    "\n",
    "## >> Cells No Mask\n",
    "* NDAcquisition-01：45,870\n",
    "* NDAcquisition-01x40：130,147\n",
    "* NDAcquisition-02Nami_x20：9,321\n",
    "* NDAcquisition-02Nami_x40：4,236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max_shape_0 , Max_shape_1\n",
    "\n",
    "\n",
    "### >> Cells \n",
    "\n",
    "    * 01x20\n",
    "        * Max_shape_0:  234\n",
    "        * Max_shape_1:  214\n",
    "\n",
    "    * 02Namix20\n",
    "        * Max_shape_0:  254\n",
    "        * Max_shape_1:  234\n",
    "\n",
    "    * 01x40\n",
    "        * Max_shape_0:  464\n",
    "        * Max_shape_1:  499\n",
    "\n",
    "    * 02Namix40\n",
    "        * Max_shape_0:  354\n",
    "        * Max_shape_1:  274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_01.shape: (45870,)\n",
      "Data_02Nami.shape: (9321,)\n"
     ]
    }
   ],
   "source": [
    "mask = False\n",
    "lens = \"20\"\n",
    "\n",
    "if mask == True:\n",
    "    Data_02Nami=np.load(\"imread_02Namix\"+str(lens)+\"_mask.npy\",allow_pickle=True)\n",
    "    Data_01=np.load(\"imread_01x\"+str(lens)+\"_mask.npy\",allow_pickle=True)\n",
    "else:\n",
    "    Data_02Nami=np.load(\"imread_02Namix\"+str(lens)+\"_nomask.npy\",allow_pickle=True)\n",
    "    Data_01=np.load(\"imread_01x\"+str(lens)+\"_nomask.npy\",allow_pickle=True)\n",
    "\n",
    "\n",
    "print(\"Data_01.shape:\", Data_01.shape)\n",
    "print(\"Data_02Nami.shape:\", Data_02Nami.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Padding Unify the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(lens) == 40:\n",
    "    Max_shape_0 = 512\n",
    "    Max_shape_1 = 512\n",
    "elif int(lens) == 20:\n",
    "    Max_shape_0 = 256\n",
    "    Max_shape_1 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPad_01:  45870\n"
     ]
    }
   ],
   "source": [
    "#　同じサイズにする \n",
    "DataPad_01=[]\n",
    "\n",
    "for img in Data_01:\n",
    "    imgSize = img.shape\n",
    "    \n",
    "    top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2\n",
    "    left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2\n",
    "    \n",
    "    if (imgSize[0] % 2) != 0:\n",
    "        top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2+1\n",
    "        \n",
    "    if (imgSize[1] % 2) != 0:     \n",
    "        left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2+1\n",
    "    \n",
    "    img_pad = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "  \n",
    "    DataPad_01.append(img_pad)\n",
    "\n",
    "print(\"DataPad_01: \",len(DataPad_01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPad_02Nami:  9321\n"
     ]
    }
   ],
   "source": [
    "#　同じサイズにする\n",
    "DataPad_02Nami=[]\n",
    "\n",
    "for img in Data_02Nami:\n",
    "    imgSize = img.shape\n",
    "    \n",
    "    top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2\n",
    "    left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2\n",
    "    \n",
    "    if (imgSize[0] % 2) != 0:\n",
    "        top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2+1\n",
    "        \n",
    "    if (imgSize[1] % 2) != 0:     \n",
    "        left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2+1\n",
    "    \n",
    "    img_pad = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "  \n",
    "    DataPad_02Nami.append(img_pad)\n",
    "\n",
    "print(\"DataPad_02Nami: \",len(DataPad_02Nami))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resize by using Bin_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBinResize = []\n",
    "# def bin_ndarray(ndarray, new_shape, operation):\n",
    "#     operation = operation.lower()\n",
    "#     if not operation in ['sum', 'mean']:\n",
    "#         raise ValueError(\"Operation not supported.\")\n",
    "#     if ndarray.ndim != len(new_shape):\n",
    "#         raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n",
    "#                                                            new_shape))\n",
    "#     compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n",
    "#                                                   ndarray.shape)]\n",
    "#     flattened = [l for p in compression_pairs for l in p]\n",
    "#     ndarray = ndarray.reshape(flattened)\n",
    "#     for i in range(len(new_shape)):\n",
    "#         op = getattr(ndarray, operation)\n",
    "#         ndarray = op(-1*(i+1))\n",
    "#     return ndarray\n",
    "\n",
    "# for img in DataResize:\n",
    "#     imgresize = bin_ndarray(img, new_shape=(512,512,3), operation='mean')\n",
    "#     DataBinResize.append(imgresize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBinResize = np.array(DataBinResize)\n",
    "# print(\"DataBinResize: \", DataBinResize.shape)\n",
    "\n",
    "# img = cv2.imread(DataPath[1])\n",
    "# print(\"DataPath[1].shape: \", img.shape)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DataResize[1].shape: \", DataResize[1].shape)\n",
    "# plt.imshow(DataResize[1])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DataBinResize[1].shape: \", DataBinResize[1].shape)\n",
    "# plt.imshow(DataBinResize[1]/255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPad_01 = DataPad_01\n",
    "DataLabel_01 = np.zeros(len(DataPad_01), dtype=np.int)\n",
    "\n",
    "DataPad_02Nami = DataPad_02Nami\n",
    "DataLabel_02Nami = np.ones(len(DataPad_02Nami), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train :  38633\n",
      "train_class_0 num :  32109\n",
      "train_class_1 num :  6524\n",
      "\n",
      "Total number of test :  16558\n",
      "test_class_0 num :  13761\n",
      "test_class_1 num :  2797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(DataPad_01, DataLabel_01,\n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(DataPad_02Nami, DataLabel_02Nami,\n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_test = np.concatenate((X_train_0, X_train_1), axis = 0), np.concatenate((X_test_0, X_test_1), axis = 0)\n",
    "y_train, y_test = np.concatenate((y_train_0, y_train_1), axis = 0), np.concatenate((y_test_0, y_test_1), axis = 0)\n",
    "\n",
    "print(\"Total number of train : \", len(y_train))\n",
    "print(\"train_class_0 num : \", y_train.tolist().count(0))\n",
    "print(\"train_class_1 num : \", y_train.tolist().count(1))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Total number of test : \", len(y_test))\n",
    "print(\"test_class_0 num : \", y_test.tolist().count(0))\n",
    "print(\"test_class_1 num : \", y_test.tolist().count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4277,
     "status": "ok",
     "timestamp": 1627022925074,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "gijcrKa5DNKm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu102'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class train_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        data = x_train.astype('float32')\n",
    "        self.x_train = []\n",
    "        for i in range(data.shape[0]):\n",
    "            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
    "        self.y_train = y_train\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x_train[idx]), torch.tensor(y_train[idx], dtype=torch.long)\n",
    "\n",
    "    \n",
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_test, y_test):\n",
    "        data = x_test.astype('float32')\n",
    "        self.x_test = []\n",
    "        for i in range(data.shape[0]):\n",
    "            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n",
    "        self.y_test = y_test\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x_test[idx]), torch.tensor(y_test[idx], dtype=torch.long)\n",
    "\n",
    "trainval_data = train_dataset(X_train, y_train)\n",
    "test_data = test_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1627023533467,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "xK5exWXUDNKn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  30907\n",
      "val_size:  7726\n",
      "test_size:  16558\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "val_size = int(len(trainval_data)*0.2)\n",
    "train_size = len(trainval_data) - val_size\n",
    "print(\"train_size: \",train_size)\n",
    "print(\"val_size: \",val_size)\n",
    "print(\"test_size: \",len(y_test))\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# ResNet遷移学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VIwIc2BXDNKp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xs6IXgvsDNKp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.resnet101(pretrained=True)\n",
    "\n",
    "#Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_fcs = model.fc.in_features\n",
    "# FC層のクラス数を変更\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_fcs, 256),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "loss_func = nn.NLLLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acd13264yb/jupyter_env/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 0.377, Accuracy: 0.918], Valid [Loss: 0.173, Accuracy: 0.965]\n",
      "EPOCH: 1, Train [Loss: 0.241, Accuracy: 0.937], Valid [Loss: 0.145, Accuracy: 0.947]\n",
      "EPOCH: 2, Train [Loss: 0.232, Accuracy: 0.944], Valid [Loss: 0.192, Accuracy: 0.952]\n",
      "EPOCH: 3, Train [Loss: 0.251, Accuracy: 0.940], Valid [Loss: 0.131, Accuracy: 0.953]\n",
      "EPOCH: 4, Train [Loss: 0.237, Accuracy: 0.940], Valid [Loss: 0.126, Accuracy: 0.964]\n",
      "EPOCH: 5, Train [Loss: 0.257, Accuracy: 0.940], Valid [Loss: 0.133, Accuracy: 0.962]\n",
      "EPOCH: 6, Train [Loss: 0.254, Accuracy: 0.941], Valid [Loss: 0.133, Accuracy: 0.960]\n",
      "EPOCH: 7, Train [Loss: 0.268, Accuracy: 0.942], Valid [Loss: 0.123, Accuracy: 0.959]\n",
      "EPOCH: 8, Train [Loss: 0.261, Accuracy: 0.943], Valid [Loss: 0.150, Accuracy: 0.968]\n",
      "EPOCH: 9, Train [Loss: 0.247, Accuracy: 0.943], Valid [Loss: 0.164, Accuracy: 0.967]\n",
      "EPOCH: 10, Train [Loss: 0.234, Accuracy: 0.943], Valid [Loss: 0.124, Accuracy: 0.967]\n",
      "EPOCH: 11, Train [Loss: 0.238, Accuracy: 0.941], Valid [Loss: 0.116, Accuracy: 0.967]\n",
      "EPOCH: 12, Train [Loss: 0.227, Accuracy: 0.945], Valid [Loss: 0.133, Accuracy: 0.967]\n",
      "EPOCH: 13, Train [Loss: 0.241, Accuracy: 0.941], Valid [Loss: 0.129, Accuracy: 0.966]\n",
      "EPOCH: 14, Train [Loss: 0.232, Accuracy: 0.944], Valid [Loss: 0.134, Accuracy: 0.969]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-87826c24d392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mn_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 勾配の初期化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jupyter_env/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_env/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_env/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "lr = 0.01\n",
    "\n",
    "# negative : ラベル0の数\n",
    "# positive : ラベル1の数\n",
    "# weight_for_0 : 1. / negative * (negative + positive)\n",
    "# weight_for_1 : 1. / positive * (negative + positive)\n",
    "# class_weight = {0 : weight_for_0, 1 : weight_for_1}\n",
    "weights = torch.tensor([(len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_01), \n",
    "                        (len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_02Nami)]).cuda()\n",
    "loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "device = \"cuda\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model)\n",
    "# model.to(device)\n",
    "\n",
    "losstrain=[]\n",
    "lossvalid=[]\n",
    "Accuracytrain=[]\n",
    "Accuracyvalid=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    # Train\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    # Visualize loss & accuracy    \n",
    "    losstrain.append(np.mean(losses_train))   \n",
    "    Accuracytrain.append(acc_train/n_train)\n",
    "    lossvalid.append(np.mean(losses_train))\n",
    "    Accuracyvalid.append(acc_val/n_val)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(epoch,np.mean(losses_train),acc_train/n_train,np.mean(losses_valid),acc_val/n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train processing plot\n",
    "epochs=range(1,n_epochs+1)\n",
    "\n",
    "plt.plot(epochs,Accuracytrain,'b',label='Training accuracy')  \n",
    "plt.plot(epochs, Accuracyvalid,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_test:  16061.0\n",
      "n_test:  16558\n",
      "Loss: 0.130, Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "losses_test = []\n",
    "n_test = 0\n",
    "acc_test = 0\n",
    "model.eval()\n",
    "\n",
    "for x, t in dataloader_test:\n",
    "    n_test += t.size()[0]\n",
    "    x = x.to(device)  # テンソルをGPUに移動\n",
    "    t = t.to(device)\n",
    "    y = model.forward(x)  # 順伝播\n",
    "    loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "    pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "    acc_test += (pred == t).float().sum().item()\n",
    "    losses_test.append(loss.tolist())\n",
    "\n",
    "# Visualize loss & accuracy \n",
    "print(\"acc_test: \", acc_test) \n",
    "print(\"n_test: \", n_test)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(np.mean(losses_test),acc_test/n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDAcquisition_01=45870\n",
    "# NDAcquisition_02Nami_x20=9321\n",
    "\n",
    "# NDAcquisition_01x40=130147\n",
    "# NDAcquisition_02Nami_x40=4236\n",
    "\n",
    "Total_number_of_train=38633\n",
    "train_class_0_num=32109\n",
    "train_class_1_num=6524\n",
    "\n",
    "Total_number_of_test=16558\n",
    "test_class_0_num=13761\n",
    "test_class_1_num=2797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7192593590259224"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_class_0_num*(train_class_0_num/Total_number_of_train) + test_class_1_num*(train_class_1_num/Total_number_of_train))/Total_number_of_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

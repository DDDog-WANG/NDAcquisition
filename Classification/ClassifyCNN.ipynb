{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの分布\n",
    "\n",
    "## >> Cells With Mask\n",
    "* NDAcquisition-01：45,723\n",
    "* NDAcquisition-01x40：130,092\n",
    "* NDAcquisition-02Nami_x20：9,096\n",
    "* NDAcquisition-02Nami_x40：4,236\n",
    "\n",
    "## >> Cells No Mask\n",
    "* NDAcquisition-01：45,870\n",
    "* NDAcquisition-01x40：130,147\n",
    "* NDAcquisition-02Nami_x20：9,321\n",
    "* NDAcquisition-02Nami_x40：4,236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max_shape_0 , Max_shape_1\n",
    "\n",
    "\n",
    "### >> Cells \n",
    "\n",
    "    * 01x20\n",
    "        * Max_shape_0:  234\n",
    "        * Max_shape_1:  214\n",
    "\n",
    "    * 02Namix20\n",
    "        * Max_shape_0:  254\n",
    "        * Max_shape_1:  234\n",
    "\n",
    "    * 01x40\n",
    "        * Max_shape_0:  464\n",
    "        * Max_shape_1:  499\n",
    "\n",
    "    * 02Namix40\n",
    "        * Max_shape_0:  354\n",
    "        * Max_shape_1:  274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_01.shape: (11990,)\n",
      "Data_02Nami.shape: (1738,)\n"
     ]
    }
   ],
   "source": [
    "Data_02Nami=np.load(\"data/imread_02Namix40.npy\",allow_pickle=True)\n",
    "Data_01=np.load(\"data/imread_01x40.npy\",allow_pickle=True)\n",
    "print(\"Data_01.shape:\", Data_01.shape)\n",
    "print(\"Data_02Nami.shape:\", Data_02Nami.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_01.shape: (11990,)\n",
      "Data_02Nami.shape: (1738,)\n"
     ]
    }
   ],
   "source": [
    "Data_01=Data_01\n",
    "Data_02Nami=Data_02Nami\n",
    "\n",
    "print(\"Data_01.shape:\", Data_01.shape)\n",
    "print(\"Data_02Nami.shape:\", Data_02Nami.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Padding Unify the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_shape_0 = 100\n",
    "Max_shape_1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPad_01:  11990\n",
      "DataPad_02Nami:  1738\n"
     ]
    }
   ],
   "source": [
    "#　同じサイズにする \n",
    "def datapadding(data):\n",
    "    DataPad=[]\n",
    "    for img in data:\n",
    "        imgSize = img.shape\n",
    "        top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2\n",
    "        left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2\n",
    "        if (imgSize[0] % 2) != 0:\n",
    "            top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2+1\n",
    "        if (imgSize[1] % 2) != 0:     \n",
    "            left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2+1\n",
    "        img_pad = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "        DataPad.append(img_pad)\n",
    "    return DataPad\n",
    "\n",
    "DataPad_01 = datapadding(Data_01)\n",
    "DataPad_02Nami = datapadding(Data_02Nami)\n",
    "print(\"DataPad_01: \",len(DataPad_01))\n",
    "print(\"DataPad_02Nami: \",len(DataPad_02Nami))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resize by using Bin_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBinResize = []\n",
    "# def bin_ndarray(ndarray, new_shape, operation):\n",
    "#     operation = operation.lower()\n",
    "#     if not operation in ['sum', 'mean']:\n",
    "#         raise ValueError(\"Operation not supported.\")\n",
    "#     if ndarray.ndim != len(new_shape):\n",
    "#         raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n",
    "#                                                            new_shape))\n",
    "#     compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n",
    "#                                                   ndarray.shape)]\n",
    "#     flattened = [l for p in compression_pairs for l in p]\n",
    "#     ndarray = ndarray.reshape(flattened)\n",
    "#     for i in range(len(new_shape)):\n",
    "#         op = getattr(ndarray, operation)\n",
    "#         ndarray = op(-1*(i+1))\n",
    "#     return ndarray\n",
    "\n",
    "# for img in DataResize:\n",
    "#     imgresize = bin_ndarray(img, new_shape=(512,512,3), operation='mean')\n",
    "#     DataBinResize.append(imgresize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBinResize = np.array(DataBinResize)\n",
    "# print(\"DataBinResize: \", DataBinResize.shape)\n",
    "\n",
    "# img = cv2.imread(DataPath[1])\n",
    "# print(\"DataPath[1].shape: \", img.shape)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DataResize[1].shape: \", DataResize[1].shape)\n",
    "# plt.imshow(DataResize[1])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DataBinResize[1].shape: \", DataBinResize[1].shape)\n",
    "# plt.imshow(DataBinResize[1]/255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPad_01 = DataPad_01\n",
    "DataLabel_01 = np.zeros(len(DataPad_01), dtype=np.int32)\n",
    "\n",
    "DataPad_02Nami = DataPad_02Nami\n",
    "DataLabel_02Nami = np.ones(len(DataPad_02Nami), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train :  9609\n",
      "train_class_0 num :  8393\n",
      "train_class_1 num :  1216\n",
      "\n",
      "Total number of test :  4119\n",
      "test_class_0 num :  3597\n",
      "test_class_1 num :  522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(DataPad_01, DataLabel_01,\n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(DataPad_02Nami, DataLabel_02Nami,\n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_test = np.concatenate((X_train_0, X_train_1), axis = 0), np.concatenate((X_test_0, X_test_1), axis = 0)\n",
    "y_train, y_test = np.concatenate((y_train_0, y_train_1), axis = 0), np.concatenate((y_test_0, y_test_1), axis = 0)\n",
    "\n",
    "print(\"Total number of train : \", len(y_train))\n",
    "print(\"train_class_0 num : \", y_train.tolist().count(0))\n",
    "print(\"train_class_1 num : \", y_train.tolist().count(1))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Total number of test : \", len(y_test))\n",
    "print(\"test_class_0 num : \", y_test.tolist().count(0))\n",
    "print(\"test_class_1 num : \", y_test.tolist().count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4277,
     "status": "ok",
     "timestamp": 1627022925074,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "gijcrKa5DNKm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu102'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class train_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        data = x_train.astype('float32')\n",
    "        self.x_train = []\n",
    "        for i in range(data.shape[0]):\n",
    "            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
    "        self.y_train = y_train\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x_train[idx]), torch.tensor(y_train[idx], dtype=torch.long)\n",
    "\n",
    "    \n",
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_test, y_test):\n",
    "        data = x_test.astype('float32')\n",
    "        self.x_test = []\n",
    "        for i in range(data.shape[0]):\n",
    "            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n",
    "        self.y_test = y_test\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x_test[idx]), torch.tensor(y_test[idx], dtype=torch.long)\n",
    "\n",
    "trainval_data = train_dataset(X_train, y_train)\n",
    "test_data = test_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1627023533467,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "xK5exWXUDNKn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  7688\n",
      "val_size:  1921\n",
      "test_size:  4119\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "val_size = int(len(trainval_data)*0.2)\n",
    "train_size = len(trainval_data) - val_size\n",
    "print(\"train_size: \",train_size)\n",
    "print(\"val_size: \",val_size)\n",
    "print(\"test_size: \",len(y_test))\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# ResNet遷移学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VIwIc2BXDNKp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xs6IXgvsDNKp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True)\n",
    "# num_fcs = model.fc.in_features\n",
    "# FC層のクラス数を変更\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(num_fcs, 512),\n",
    "#     # nn.Dropout(p=0.5),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(256, 2)\n",
    "# )\n",
    "\n",
    "model = torch.load(\"SelfResnet18_300.pkl\")\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 512),\n",
    "    # nn.Dropout(p=0.5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "#Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "loss_func = nn.NLLLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 0.173, Accuracy: 0.957], Valid [Loss: 0.180, Accuracy: 0.969]\n",
      "EPOCH: 1, Train [Loss: 0.152, Accuracy: 0.964], Valid [Loss: 0.114, Accuracy: 0.967]\n",
      "EPOCH: 2, Train [Loss: 0.131, Accuracy: 0.962], Valid [Loss: 0.111, Accuracy: 0.965]\n",
      "EPOCH: 3, Train [Loss: 0.124, Accuracy: 0.964], Valid [Loss: 0.101, Accuracy: 0.969]\n",
      "EPOCH: 4, Train [Loss: 0.136, Accuracy: 0.967], Valid [Loss: 0.097, Accuracy: 0.971]\n",
      "EPOCH: 5, Train [Loss: 0.135, Accuracy: 0.953], Valid [Loss: 0.102, Accuracy: 0.976]\n",
      "EPOCH: 6, Train [Loss: 0.128, Accuracy: 0.966], Valid [Loss: 0.108, Accuracy: 0.968]\n",
      "EPOCH: 7, Train [Loss: 0.128, Accuracy: 0.968], Valid [Loss: 0.110, Accuracy: 0.967]\n",
      "EPOCH: 8, Train [Loss: 0.122, Accuracy: 0.965], Valid [Loss: 0.133, Accuracy: 0.974]\n",
      "EPOCH: 9, Train [Loss: 0.122, Accuracy: 0.964], Valid [Loss: 0.109, Accuracy: 0.969]\n",
      "EPOCH: 10, Train [Loss: 0.128, Accuracy: 0.966], Valid [Loss: 0.095, Accuracy: 0.971]\n",
      "EPOCH: 11, Train [Loss: 0.125, Accuracy: 0.963], Valid [Loss: 0.109, Accuracy: 0.966]\n",
      "EPOCH: 12, Train [Loss: 0.119, Accuracy: 0.965], Valid [Loss: 0.133, Accuracy: 0.950]\n",
      "EPOCH: 13, Train [Loss: 0.122, Accuracy: 0.965], Valid [Loss: 0.108, Accuracy: 0.968]\n",
      "EPOCH: 14, Train [Loss: 0.127, Accuracy: 0.965], Valid [Loss: 0.103, Accuracy: 0.972]\n",
      "EPOCH: 15, Train [Loss: 0.173, Accuracy: 0.968], Valid [Loss: 0.164, Accuracy: 0.970]\n",
      "EPOCH: 16, Train [Loss: 0.144, Accuracy: 0.963], Valid [Loss: 0.105, Accuracy: 0.968]\n",
      "EPOCH: 17, Train [Loss: 0.125, Accuracy: 0.965], Valid [Loss: 0.119, Accuracy: 0.964]\n",
      "EPOCH: 18, Train [Loss: 0.123, Accuracy: 0.961], Valid [Loss: 0.114, Accuracy: 0.970]\n",
      "EPOCH: 19, Train [Loss: 0.130, Accuracy: 0.963], Valid [Loss: 0.101, Accuracy: 0.966]\n",
      "EPOCH: 20, Train [Loss: 0.133, Accuracy: 0.960], Valid [Loss: 0.101, Accuracy: 0.969]\n",
      "EPOCH: 21, Train [Loss: 0.127, Accuracy: 0.968], Valid [Loss: 0.121, Accuracy: 0.968]\n",
      "EPOCH: 22, Train [Loss: 0.120, Accuracy: 0.964], Valid [Loss: 0.110, Accuracy: 0.967]\n",
      "EPOCH: 23, Train [Loss: 0.122, Accuracy: 0.965], Valid [Loss: 0.103, Accuracy: 0.969]\n",
      "EPOCH: 24, Train [Loss: 0.128, Accuracy: 0.965], Valid [Loss: 0.104, Accuracy: 0.971]\n",
      "EPOCH: 25, Train [Loss: 0.140, Accuracy: 0.968], Valid [Loss: 0.295, Accuracy: 0.970]\n",
      "EPOCH: 26, Train [Loss: 0.121, Accuracy: 0.968], Valid [Loss: 0.140, Accuracy: 0.968]\n",
      "EPOCH: 27, Train [Loss: 0.117, Accuracy: 0.966], Valid [Loss: 0.100, Accuracy: 0.973]\n",
      "EPOCH: 28, Train [Loss: 0.116, Accuracy: 0.970], Valid [Loss: 0.102, Accuracy: 0.976]\n",
      "EPOCH: 29, Train [Loss: 0.119, Accuracy: 0.971], Valid [Loss: 0.104, Accuracy: 0.969]\n",
      "EPOCH: 30, Train [Loss: 0.120, Accuracy: 0.965], Valid [Loss: 0.108, Accuracy: 0.965]\n",
      "EPOCH: 31, Train [Loss: 0.135, Accuracy: 0.965], Valid [Loss: 0.106, Accuracy: 0.968]\n",
      "EPOCH: 32, Train [Loss: 0.139, Accuracy: 0.968], Valid [Loss: 0.103, Accuracy: 0.967]\n",
      "EPOCH: 33, Train [Loss: 0.122, Accuracy: 0.960], Valid [Loss: 0.104, Accuracy: 0.972]\n",
      "EPOCH: 34, Train [Loss: 0.116, Accuracy: 0.969], Valid [Loss: 0.099, Accuracy: 0.967]\n",
      "EPOCH: 35, Train [Loss: 0.115, Accuracy: 0.968], Valid [Loss: 0.113, Accuracy: 0.962]\n",
      "EPOCH: 36, Train [Loss: 0.116, Accuracy: 0.964], Valid [Loss: 0.103, Accuracy: 0.967]\n",
      "EPOCH: 37, Train [Loss: 0.120, Accuracy: 0.963], Valid [Loss: 0.101, Accuracy: 0.968]\n",
      "EPOCH: 38, Train [Loss: 0.119, Accuracy: 0.961], Valid [Loss: 0.107, Accuracy: 0.973]\n",
      "EPOCH: 39, Train [Loss: 0.111, Accuracy: 0.969], Valid [Loss: 0.111, Accuracy: 0.968]\n",
      "EPOCH: 40, Train [Loss: 0.111, Accuracy: 0.964], Valid [Loss: 0.107, Accuracy: 0.967]\n",
      "EPOCH: 41, Train [Loss: 0.124, Accuracy: 0.963], Valid [Loss: 0.102, Accuracy: 0.967]\n",
      "EPOCH: 42, Train [Loss: 0.130, Accuracy: 0.967], Valid [Loss: 0.104, Accuracy: 0.968]\n",
      "EPOCH: 43, Train [Loss: 0.113, Accuracy: 0.965], Valid [Loss: 0.121, Accuracy: 0.956]\n",
      "EPOCH: 44, Train [Loss: 0.114, Accuracy: 0.967], Valid [Loss: 0.107, Accuracy: 0.967]\n",
      "EPOCH: 45, Train [Loss: 0.118, Accuracy: 0.964], Valid [Loss: 0.101, Accuracy: 0.973]\n",
      "EPOCH: 46, Train [Loss: 0.118, Accuracy: 0.963], Valid [Loss: 0.142, Accuracy: 0.967]\n",
      "EPOCH: 47, Train [Loss: 0.108, Accuracy: 0.968], Valid [Loss: 0.116, Accuracy: 0.970]\n",
      "EPOCH: 48, Train [Loss: 0.121, Accuracy: 0.970], Valid [Loss: 0.115, Accuracy: 0.964]\n",
      "EPOCH: 49, Train [Loss: 0.137, Accuracy: 0.964], Valid [Loss: 0.114, Accuracy: 0.968]\n",
      "EPOCH: 50, Train [Loss: 0.118, Accuracy: 0.966], Valid [Loss: 0.099, Accuracy: 0.970]\n",
      "EPOCH: 51, Train [Loss: 0.119, Accuracy: 0.966], Valid [Loss: 0.102, Accuracy: 0.973]\n",
      "EPOCH: 52, Train [Loss: 0.118, Accuracy: 0.957], Valid [Loss: 0.109, Accuracy: 0.962]\n",
      "EPOCH: 53, Train [Loss: 0.118, Accuracy: 0.961], Valid [Loss: 0.108, Accuracy: 0.967]\n",
      "EPOCH: 54, Train [Loss: 1.933, Accuracy: 0.965], Valid [Loss: 0.100, Accuracy: 0.967]\n",
      "EPOCH: 55, Train [Loss: 0.118, Accuracy: 0.959], Valid [Loss: 0.119, Accuracy: 0.964]\n",
      "EPOCH: 56, Train [Loss: 0.117, Accuracy: 0.963], Valid [Loss: 0.102, Accuracy: 0.967]\n",
      "EPOCH: 57, Train [Loss: 0.116, Accuracy: 0.965], Valid [Loss: 0.154, Accuracy: 0.966]\n",
      "EPOCH: 58, Train [Loss: 0.110, Accuracy: 0.956], Valid [Loss: 0.109, Accuracy: 0.964]\n",
      "EPOCH: 59, Train [Loss: 0.109, Accuracy: 0.963], Valid [Loss: 0.109, Accuracy: 0.968]\n",
      "EPOCH: 60, Train [Loss: 0.143, Accuracy: 0.966], Valid [Loss: 0.112, Accuracy: 0.966]\n",
      "EPOCH: 61, Train [Loss: 0.137, Accuracy: 0.961], Valid [Loss: 0.105, Accuracy: 0.969]\n",
      "EPOCH: 62, Train [Loss: 0.118, Accuracy: 0.961], Valid [Loss: 0.116, Accuracy: 0.959]\n",
      "EPOCH: 63, Train [Loss: 0.117, Accuracy: 0.962], Valid [Loss: 0.105, Accuracy: 0.969]\n",
      "EPOCH: 64, Train [Loss: 0.109, Accuracy: 0.959], Valid [Loss: 0.107, Accuracy: 0.964]\n",
      "EPOCH: 65, Train [Loss: 0.109, Accuracy: 0.964], Valid [Loss: 0.103, Accuracy: 0.966]\n",
      "EPOCH: 66, Train [Loss: 0.108, Accuracy: 0.964], Valid [Loss: 0.115, Accuracy: 0.960]\n",
      "EPOCH: 67, Train [Loss: 0.119, Accuracy: 0.963], Valid [Loss: 0.109, Accuracy: 0.967]\n",
      "EPOCH: 68, Train [Loss: 0.114, Accuracy: 0.962], Valid [Loss: 0.105, Accuracy: 0.966]\n",
      "EPOCH: 69, Train [Loss: 0.113, Accuracy: 0.957], Valid [Loss: 0.113, Accuracy: 0.965]\n",
      "EPOCH: 70, Train [Loss: 0.112, Accuracy: 0.962], Valid [Loss: 0.517, Accuracy: 0.969]\n",
      "EPOCH: 71, Train [Loss: 0.109, Accuracy: 0.961], Valid [Loss: 0.106, Accuracy: 0.971]\n",
      "EPOCH: 72, Train [Loss: 0.113, Accuracy: 0.964], Valid [Loss: 0.113, Accuracy: 0.967]\n",
      "EPOCH: 73, Train [Loss: 0.111, Accuracy: 0.966], Valid [Loss: 0.105, Accuracy: 0.967]\n",
      "EPOCH: 74, Train [Loss: 0.112, Accuracy: 0.964], Valid [Loss: 0.109, Accuracy: 0.966]\n",
      "EPOCH: 75, Train [Loss: 0.115, Accuracy: 0.966], Valid [Loss: 0.111, Accuracy: 0.971]\n",
      "EPOCH: 76, Train [Loss: 0.107, Accuracy: 0.967], Valid [Loss: 0.120, Accuracy: 0.969]\n",
      "EPOCH: 77, Train [Loss: 0.110, Accuracy: 0.967], Valid [Loss: 0.114, Accuracy: 0.966]\n",
      "EPOCH: 78, Train [Loss: 0.128, Accuracy: 0.965], Valid [Loss: 0.127, Accuracy: 0.966]\n",
      "EPOCH: 79, Train [Loss: 0.126, Accuracy: 0.965], Valid [Loss: 0.111, Accuracy: 0.968]\n",
      "EPOCH: 80, Train [Loss: 0.114, Accuracy: 0.963], Valid [Loss: 0.109, Accuracy: 0.965]\n",
      "EPOCH: 81, Train [Loss: 0.107, Accuracy: 0.966], Valid [Loss: 0.105, Accuracy: 0.969]\n",
      "EPOCH: 82, Train [Loss: 0.135, Accuracy: 0.965], Valid [Loss: 0.109, Accuracy: 0.972]\n",
      "EPOCH: 83, Train [Loss: 0.132, Accuracy: 0.963], Valid [Loss: 0.115, Accuracy: 0.974]\n",
      "EPOCH: 84, Train [Loss: 0.131, Accuracy: 0.966], Valid [Loss: 0.119, Accuracy: 0.969]\n",
      "EPOCH: 85, Train [Loss: 0.124, Accuracy: 0.965], Valid [Loss: 0.110, Accuracy: 0.968]\n",
      "EPOCH: 86, Train [Loss: 0.115, Accuracy: 0.967], Valid [Loss: 0.120, Accuracy: 0.972]\n",
      "EPOCH: 87, Train [Loss: 0.123, Accuracy: 0.967], Valid [Loss: 0.110, Accuracy: 0.970]\n",
      "EPOCH: 88, Train [Loss: 0.111, Accuracy: 0.967], Valid [Loss: 0.115, Accuracy: 0.968]\n",
      "EPOCH: 89, Train [Loss: 0.118, Accuracy: 0.965], Valid [Loss: 0.116, Accuracy: 0.968]\n",
      "EPOCH: 90, Train [Loss: 0.111, Accuracy: 0.966], Valid [Loss: 0.292, Accuracy: 0.968]\n",
      "EPOCH: 91, Train [Loss: 0.119, Accuracy: 0.965], Valid [Loss: 0.112, Accuracy: 0.968]\n",
      "EPOCH: 92, Train [Loss: 0.116, Accuracy: 0.963], Valid [Loss: 0.118, Accuracy: 0.967]\n",
      "EPOCH: 93, Train [Loss: 0.115, Accuracy: 0.964], Valid [Loss: 0.123, Accuracy: 0.970]\n",
      "EPOCH: 94, Train [Loss: 0.117, Accuracy: 0.964], Valid [Loss: 0.121, Accuracy: 0.967]\n",
      "EPOCH: 95, Train [Loss: 0.115, Accuracy: 0.963], Valid [Loss: 0.110, Accuracy: 0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 96, Train [Loss: 0.113, Accuracy: 0.963], Valid [Loss: 0.117, Accuracy: 0.970]\n",
      "EPOCH: 97, Train [Loss: 0.113, Accuracy: 0.966], Valid [Loss: 0.113, Accuracy: 0.971]\n",
      "EPOCH: 98, Train [Loss: 0.118, Accuracy: 0.961], Valid [Loss: 0.121, Accuracy: 0.966]\n",
      "EPOCH: 99, Train [Loss: 0.114, Accuracy: 0.964], Valid [Loss: 0.117, Accuracy: 0.973]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "# negative : ラベル0の数\n",
    "# positive : ラベル1の数\n",
    "# weight_for_0 : 1. / negative * (negative + positive)\n",
    "# weight_for_1 : 1. / positive * (negative + positive)\n",
    "# class_weight = {0 : weight_for_0, 1 : weight_for_1}\n",
    "weights = torch.tensor([(len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_01), \n",
    "                        (len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_02Nami)]).cuda()\n",
    "loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # 定义优化器\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99) # 定义衰减策略\n",
    "\n",
    "device = \"cuda\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model)\n",
    "# model.to(device)\n",
    "\n",
    "losstrain=[]\n",
    "lossvalid=[]\n",
    "Accuracytrain=[]\n",
    "Accuracyvalid=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    # Train\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    scheduler.step()\n",
    "    # Visualize loss & accuracy    \n",
    "    losstrain.append(np.mean(losses_train))   \n",
    "    Accuracytrain.append(acc_train/n_train)\n",
    "    lossvalid.append(np.mean(losses_train))\n",
    "    Accuracyvalid.append(acc_val/n_val)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(epoch,np.mean(losses_train),acc_train/n_train,np.mean(losses_valid),acc_val/n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAseklEQVR4nO3deXxU9b3/8dcnCSQkgUDCToCkCCgCYYmo4IJrQf1BtYpQN4rVSt3QWmurVa62t9fqbdVWvcVaEfQW1Coiiwsq4hVQwhJkJyxCWEMICSGEbN/fH2cSh5CQIQQSDu/n45EHc875zjmfM2fmPWe+c+aLOecQEZFTX1h9FyAiInVDgS4i4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQPcpM5ttZrfVddv6ZGabzezyE7DeuWb2s8Dtm8zs41Da1mI7ncws38zCa1uryNEo0BuQwIu9/K/MzA4GTd90LOtyzg11zr1e120bIjN7xMzmVTG/pZkVmVnPUNflnHvTOXdlHdV12BuQc26Lcy7WOVdaF+sXqUyB3oAEXuyxzrlYYAvw/4LmvVnezswi6q/KBukNYKCZJVeaPxL41jm3oh5qOm3o+dhwKNBPAWY22MwyzezXZrYTeM3MWpjZDDPLMrOcwO3EoPsEdyOMNrP/M7NnA203mdnQWrZNNrN5ZrbfzOaY2Ytm9kY1dYdS41Nm9lVgfR+bWcug5beY2Xdmlm1mj1b3+DjnMoHPgFsqLboVmFRTHZVqHm1m/xc0fYWZrTGzXDP7G2BBy7qY2WeB+vaY2Ztm1jywbDLQCfgg8AnrYTNLMjNXHoBm1t7MppvZXjPLMLM7gtY93szeMrNJgcdmpZmlVvcYmNnzZrbVzPLMbLGZXRi0LNzMfmtmGwLrWmxmHQPLzjazTwI17DKz3wbmTzSz3wetY7CZZQZNbw48H5cDB8wsIvBJqXwbq8zs2ko13mFmq4OW9zOzX5nZvyu1e8HMnq9uX6V6CvRTR1sgHugM3Il37F4LTHcCDgJ/O8r9zwXWAi2BPwGvmpnVou3/At8ACcB4jgzRYKHU+BPgp0BroDHwEICZ9QBeDqy/fWB7VYZwwOvBtZhZd6BPoN5jfazK19ESeBd4DO+x2AAMCm4C/DFQ31lAR7zHBOfcLRz+KetPVWxiCpAZuP/1wH+a2aVBy4cF2jQHptdQ86LA/sYH9vltM4sKLHsQGAVcBTQDxgAFZtYUmAN8GKjhDODTo2yjslHA1UBz51wJ3uNzIRAH/Afwhpm1AzCzG/Aem1sDNQwDsvE+XQ0JeiOMwPtkNekY6pByzjn9NcA/YDNweeD2YKAIiDpK+z5ATtD0XOBngdujgYygZdGAA9oeS1u8MCwBooOWvwG8EeI+VVXjY0HTvwA+DNx+HJgStCwm8BhcXs26o4E8YGBg+g/A+7V8rP4vcPtWYGFQO8ML4J9Vs94fAUurOoaB6aTAYxmBF/6lQNOg5X8EJgZujwfmBC3rARw8hudPDpASuL0WGF5Fm1HB9VZaNhH4fdD0YCCz0r6NqaGGZeXbBT4C7q+m3WzgjsDta4BVx/v6OV3/dIZ+6shyzhWWT5hZtJn9PdAlkQfMA5pb9VdQ7Cy/4ZwrCNyMPca27YG9QfMAtlZXcIg17gy6XRBUU/vgdTvnDuCd0VUpUNPbwK2BTxM3ETjLq8VjVa5yDS542szamNkUM9sWWO8beGfyoSh/LPcHzfsO6BA0XfmxibJq+qvN7KFAd0aume3DO0sur6Uj3tlzZdXND9Vhx97MbjWzZWa2L1BDzxBqAO/T1c2B2zcDk4+jptOaAv3UUXlYzF8C3YFznXPNgIsC86vrRqkLO4B4M4sOmtfxKO2Pp8YdwesObDOhhvu8DowArgCaAh8cZx2VazAO39//xDsuvQLrvbnSOo82lOl2vMeyadC8TsC2Gmo6QqC//GG8fW/hnGsO5AbVshXoUsVdtwI/qGa1B/A+9ZRrW0Wbiv0zs87AK8A9QEKghhUh1AAwDeht3tVI1wBvVtNOaqBAP3U1xesL3mdm8cATJ3qDzrnvgDRgvJk1NrPzgf93gmp8B7jGzC4ws8bAk9T8fP0S2AdMwOuuKTrOOmYCZ5vZdYEz4/s4PNiaAvlArpl1AH5V6f67qCYwnXNbgfnAH80sysx6A7fjneUfq6Z4XWFZQISZPY7XT13uH8BTZtbVPL3NLAGYAbQzs3FmFmlmTc3s3MB9lgFXmVm8mbUFxtVQQwxewGcBmNlP8c7Qg2t4yMz6B2o4I/AmQOCT5zsEvp9xzm2pxWMgKNBPZc8BTYA9wEK8L7ZOhpuA8/G6P34PTAUOVdP2OWpZo3NuJXA33ot8B16fcGYN93F43SydOfxLtVrV4ZzbA9wA/Bfe/nYFvgpq8h9AP7yz4Zl4X6AG+yPwWKAL4qEqNjEKr199O/Ae8IRzbk4otVXyEd4+rcPrtink8O6QPwNvAR/jfc/wKtAk0N1zBd6b8k5gPXBJ4D6TgXS8vvKP8Y5ztZxzq4D/BhbgvZH1Iuixcs69jfe9xv8C+/HOyuODVvF64D7qbjkOFvgiQqRWzGwqsMY5d8I/IYh/mVknYA3eF/V59V3PqUpn6HJMzOwc866/DjOzIcBwvLMtkVoxszC8SyunKMyPT42Bbmb/NLPdZlblr+0C/WEvmPfDiOVm1q/uy5QGpC3eZX75wAvAWOfc0nqtSE5ZZhaD1w10BSfheyC/q7HLxcwuwnvxTnLOHTEmhpldBdyL96OFc4HnnXPnVm4nIiInVo1n6M65ecDeozQZjhf2zjm3EO/63nZ1VaCIiISmLgbV6cDh36hnBubtqNzQzO7E+9k6MTEx/c8888w62LyIyOlj8eLFe5xzrapadlJHSXPOTcC7RpjU1FSXlpZ2MjcvInLKM7PvqltWF1e5bOPwX88lUotfu4mIyPGpi0CfTmD8DDM7D8h1zh3R3SIiIidWjV0uZvYvvJHWWpo3HvITQCMA59z/ALPwrnDJwBtA6Kcnqtg6UVoK4fofwI7gHBQVQWRkfVciIrVUY6A750bVsNzh/US7YTp0CFavhg8/hJkzYf58GDwYfv97OP/8I9t/9RU8/TTExMCdd3pty4cCLy31boeF8MHGOfj2W+8vKQm6doVWrb5f14nkHOzeDQcPQvv20LjxkW3KymDuXJgxA5Ytg/R0yMuDG26ABx+E1Gr/L4Wqt7dsGXTqBAk1jZ9VSU4OvPkm7NkDN94IZ511bPevzpYtMH26d4z796/dOkpLYdUqWLgQ2rSBYcPqprZTRXExNGoUevu9e73nd4sWdVfD9u2weDGsW+f97d4NQ4bAiBFVb6ewEJYsgbg46NIFoqKObHOiFRVBdrZXS1LS4a/5nBx49lkYM8arr47V20//a/2l6LvvwuuvQ7duXkh26+b9tQtcKblunRfcc+bAmjW4777Dysq8ZX37ei/wd96B3btxQ69i34Ar2Vkcz668aHoseJXWi2fjWrfGiou9B797d+9v/XrYsAGaNoUf/cgLvksvPfIJv2UL/PGPXg1bDx9Z9lCTOOjajche3eDMM+Hqq6FPH++AHzwIkyd74ZaU5K37wgthxw5YsAAWLQLncPEJbD+UQFmLBDr0TiCsZbwXxOVP+PXrvX/zvv/B3cG4NuQ060xu627ktu1GDAV0S3uTyF1bcVFR5CT2YjkpZGY1ZnjeZJq6/SwIG8j6lBvoct/VnH9rV8JKirxwW7OGQqLIyElg044oLsqbQdz0ybBpEzRqRMkPr+b9uFv5OuEq4ttF0qqVt6v9+0NUUZ73GGZne38ffghTp3r7bgbOsbtzKl+3HkbSeW0584IEGiXEHf6GevAgxXkH2Z7ThOgR19CydRhmXvZs3uQoePdDun/2ElGfzvLetMB7HO+9Fw4coHD2ZxR9/hUbm6bwj1a/ZXZWKt27w313FnJl1DzC0pfCunW4desgPR3bHzS67Zgx8Le/QZMm3nRODixf7oVGkyYQHw8dOhz+As7LgxUroGVLb1lMzJHP6b174YsvoFkz77ncocP3x33JEq/+oUO/b19U5IVCTo5XUyhvggcOwNKlXtAlJHh/wZ/G9u2Djz+ueN2wfj3s3OkdvEsv9U5sAm/WpaUQ1rol1jERmjeHTz+Fv/8d9/77WEkJRe06sa9TCnuT+7O/5/kU9h5A047N6dzZa26lJfDdd97ztLAQevb0ws0M1q6Fzz7zHo+FC73XU7mWLSE2FjZvhshISq8cSlhSJyy6CYSF4b7+Gr76CjvkDS3kzChu24niDkkUt02ktF0ikfGxRMdAWNAhKi7xhoSMKD+9jYz0jmVCgldferr3l5Pj1ZqS4tVbVOQ9d/fs8U7cli3zHrug1x49e8Jdd8Hw4fDaa/Df/w25ufDSSzB2bM3HrQpmttg5V+UZ16kX6JMmwZ/+BBkZ3tl3QGmTGIhrTvhO7/vY7S16sCKsN2m53VhR0p3k0YN56tX23sl1fj5bH/kbMS89Q7z7/hL7bOJ5ml8zJf5uOieHcV3p21yz4xWaFO4lI6w73xZ2pT3bGFo8neiS/eS078Gzw77k6/XxZGZCo+IC3tl6Lp1KNjAvegjzYq9mfskAmmRvpRvr6MY6urKe3lHraH1oK+Ycu2K7sKjJRQzeP53YwmyKu55FWHYW4Xv3HL7fSUkUlEZStDObpsV7CafssMVlGFnRndka2ZXNkd3Z1Kgb23KiicvPJJFMktlEV9bTmS2UEM5H/JBJ3MoMG0aBa0KLFt7rtmNcHoM3/ZNzlr1C+5xVAOwIa0/Lst00ouSIw1GGsaHzZXR48EYy56yh+cw3aF22i1ya8T7D+Tc/pjn7uNHe5go+ppErrrhvSVQM+cNuIubBn7Noewe+uvt/uWLH6/QhPaSnwnv8iDui3iCmdQx7th3ihdJfcDv/ZAdtea/F7ey4eCQD8z9m4OIXiMvxLgzYTSsWcD4XM4/m7GNZmyvZua8JFxyaQywHANgT0Ya1Zd1IL+vJAs7na87lrpjJPHjg97i+fbGHHvJOLD74wHtRByls0ZbGF55H2A+SYMECXFoaVvr9/wmd36gFZV3OoFn/bt6np/nzcQsWfH/SARyiMZEcvl7uvNMLg927KRs5irBF3+AiIrCSErj4Yujfn5I1GRxYtp780igW9/opS3veApGRXLT6fzjv8z/SZH/W4ets1Qo6dvQC7JtvoLSUsrjmlJ7ZE9etG7Rrz8GvFhOdNo9Ghw5UeQxKwyIILyshJzyBSTaa7SWtSCGdFNI5i9WE4SjD2Es8DsMMmrlcGlN82HqKGsdQGhVDk7zdAGwLS2RJ5EC+jT2fDQkDCOtxJh1T4mnbxrH7wyV0+mISF+W8T3P2EU0BEZTwbVgKn5ZdwjwuIpoCurKerqynE1voyFY6sO2I7YaiNCyC7c17kN+oBR33fUvsoSN/llMc05x9nVPY1aonG/LbsHJnAnt3l3BX9Ouckbukot22c37E5DP+g8H39ea88465FMBngV5a6r2O/vxsGd99tbUiJLuxjjbs4ksuZCZXk9e8Mykp3glwXp735njzzd6/n3wC118PbVqV8bt799E1PpuOsTlsjzuLJeubkp7unUDs2uWdpERGwhlneG/KBQWwZH4hfTa9y0RGMz/sAn7T50M6dmnM2MW3c/HG13j20tksb/dDSku9+/brBwMGeCcYb7wBr74KBzP38COmcUvk25xXPI+Pw4bwTMkDfMmFGI6erGAQX7Gd9iwKO4/w9m3IzPQ+iPzm12W0isxjwYxsVn2Zze4DMeS27EJcmyiaNfO2GRkJbdt62x0wwKu/tBSKcwvIzSpi9Y7mrFnjnSxceSUMHBh0hhJwaPVGvn16JoWfL2BXVGe2NE9hR/zZdOlUTK/22bSLzuW5hefx1/cSiYz0Tmb69S5h8q2f0GPFW7hp07B9+wDIadaJ2bE38En+QDbmtWQPCWwmiQJiCA/3auvc2Tvx/H+XFTDvvWw+fyebdWl5ZGdDaRmUEUZ8+yakXhTN1WGz6fuvX7G9VR9eSf07t6ffS6dtC9l40++Y1ut3fDG/EQsXeidPVlbCYOYS1rYN/W89m5E/CaN3Uh729/+Bv/wF17gxGd2v4R87rmZe6SBanRFHcjK0bu09jo0bex8K2y6ZydRGNxNbvI/86FZ80PQmXt81hDBKaRZxkKSonZydv5BB4Qvp5L5jRZMBfHDgUr5mAM3ZR5fGmSSHfUeHwgz6xq4noWArecl9eLvgal7b8UMiOcSFbdbTPy6DlbmJvLfrfFbRgyfCf88vS//ElvBk4kv3UIZxO6/ylV3Ir9tM5OaCvxOXv411rivrXFc6ksk5LKKAJuTRjLbsYg6X8SJ3E0EJCWTT1nYzIHEbKQmZJETksjL+Il7acg0T15xLGYd/xxRBMec0Sqd7xwI6d4bE9mWU7NzDoY2ZhO3YxobYPmzs+2O6nB1FcrL3PtWuHUSX5NE4fRFNli2gbPsO8vfD/v2wt6QZ30V2Y1OjbuzOiyRu83K6H0qnBTksiryQPb0vpWnKDygpNQoKvBPjdeu816Rz3ln+oEHe87qoCLKyICe7jHYdwujWzXudNm7sne8dOgQlJd6HtZKiMnKyy9i50+vJAe8kPD7eW75nj9ejs3fbQfI276VoRzaHSsPZ2OhMYuIjadIEig454g9uo+WB78grjqKAaHKJYwftKB/6vUULr7bOnb1evw470/hRo5lMK76axaQSHQ1//av34ao2fBXojz8OTz3lPVjjxsEtt3gHYc0a2LbN64Xp2dN7UpV/8nUO/vM/4bHH4NxzIS3N+9Q0c6YXerWxeze4SZNo86vb4PbbvY/Fo0fDo496/fNHUVoKK1d6Xc7Nm3vzSkq8rsIFC7wnY+vW3hNt+3Zv3zIyvN6iO+/8/hN/+b7Byemar87SpfDcc163yi9+EfTGUFQE8+Z5XQnnnFNRZEmJ9yLcsuX7XqLmzb1PoMH7Vq6szGtfWOg9ZhX7OnMmjBwJ+fleV8akSXDddYfd1zmvtyE/33tMq/z6w7kaH8CSEvjzn+F/Ht9O50NrWRB2Af3Pa8QVV8All3jPq4gImD0bXnkF/m9eGSl9w7joIi98evb0Qu7gQXjiCW9djSPKKCwKIznZe25ef733UJXLyIBZs7znQPv1XzDq49HkxbZnxsg3adwtiV27vOfL1wsdjRs5brgxjFGjvDfnsGVLvG6QbdspGPtL9vQczN693uOYleX1EPzrX4f3aKSkeF3TTZt6QVha6oVjz57eCUHlN/y64px34rR/v7e96q5ZOHjQa9e5c2hfYx2v0lLvKVzVc9I5r5dq+3av97C8161Zs8OfoyUl8NFH3ldVXbp4MdGv37F9NVHZ0QK93v7vu/79+7va2LDBualTnSsuPvb7/vWvzoFzV17pXF5erTZ/pEcf9VYaHu7cxRfXrjCpvfR05266ybnly0/K5jZtcm7GDOdyco5vPYsWeWW/8opzRUUh3qm01Lmysipnl5Yeew2lpc598YVzTz/t3LJlx35/qR9AmqsmV0+5M/TjtWmT121YZ2cbZWVw223eFSPffPP9l7MiIifA0c7QT+pP/xuC5OQ6XmFYmHd1yrFe4iUiUsf0H1zUFYW5iNQzBbqIiE8o0EVEfEKBLiLiEwp0ERGfUKCLiPiEAl1ExCcU6CIiPqFAFxHxCQW6iIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE8o0EVEfEKBLiLiEyEFupkNMbO1ZpZhZo9UsbyTmX1uZkvNbLmZXVX3pYqIyNHUGOhmFg68CAwFegCjzKxHpWaPAW855/oCI4GX6rpQERE5ulDO0AcAGc65jc65ImAKMLxSGwc0C9yOA7bXXYkiIhKKUAK9A7A1aDozMC/YeOBmM8sEZgH3VrUiM7vTzNLMLC0rK6sW5YqISHXq6kvRUcBE51wicBUw2cyOWLdzboJzLtU5l9qqVas62rSIiEBogb4N6Bg0nRiYF+x24C0A59wCIApoWRcFiohIaEIJ9EVAVzNLNrPGeF96Tq/UZgtwGYCZnYUX6OpTERE5iWoMdOdcCXAP8BGwGu9qlpVm9qSZDQs0+yVwh5mlA/8CRjvn3IkqWkREjhQRSiPn3Cy8LzuD5z0edHsVMKhuSxMRkWOhX4qKiPiEAl1ExCcU6CIiPqFAFxHxCQW6iIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE8o0EVEfEKBLiLiEwp0ERGfUKCLiPiEAl1ExCcU6CIiPqFAFxHxCQW6iIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQnQgp0MxtiZmvNLMPMHqmmzQgzW2VmK83sf+u2TBERqUlETQ3MLBx4EbgCyAQWmdl059yqoDZdgd8Ag5xzOWbW+kQVLCIiVQvlDH0AkOGc2+icKwKmAMMrtbkDeNE5lwPgnNtdt2WKiEhNQgn0DsDWoOnMwLxg3YBuZvaVmS00syFVrcjM7jSzNDNLy8rKql3FIiJSpbr6UjQC6AoMBkYBr5hZ88qNnHMTnHOpzrnUVq1a1dGmRUQEQgv0bUDHoOnEwLxgmcB051yxc24TsA4v4EVE5CQJJdAXAV3NLNnMGgMjgemV2kzDOzvHzFridcFsrLsyRUSkJjUGunOuBLgH+AhYDbzlnFtpZk+a2bBAs4+AbDNbBXwO/Mo5l32iihYRkSOZc65eNpyamurS0tLqZdsiIqcqM1vsnEutapl+KSoi4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE8o0EVEfEKBLiLiEwp0ERGfUKCLiPiEAl1ExCcU6CIiPqFAFxHxCQW6iIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI+ERIgW5mQ8xsrZllmNkjR2n3YzNzZpZadyWKiEgoagx0MwsHXgSGAj2AUWbWo4p2TYH7ga/rukgREalZKGfoA4AM59xG51wRMAUYXkW7p4CngcI6rE9EREIUSqB3ALYGTWcG5lUws35AR+fczKOtyMzuNLM0M0vLyso65mJFRKR6x/2lqJmFAX8GfllTW+fcBOdcqnMutVWrVse7aRERCRJKoG8DOgZNJwbmlWsK9ATmmtlm4Dxgur4YFRE5uUIJ9EVAVzNLNrPGwEhgevlC51yuc66lcy7JOZcELASGOefSTkjFIiJSpRoD3TlXAtwDfASsBt5yzq00syfNbNiJLlBEREITEUoj59wsYFaleY9X03bw8ZclIiLHSr8UFRHxCQW6iIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE8o0EVEfEKBLiLiEwp0ERGfUKCLiPiEAl1ExCcU6CIiPqFAFxHxCQW6iIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQnFOgiIj6hQBcR8QkFuoiIT4QU6GY2xMzWmlmGmT1SxfIHzWyVmS03s0/NrHPdlyoiIkdTY6CbWTjwIjAU6AGMMrMelZotBVKdc72Bd4A/1XWhIiJydKGcoQ8AMpxzG51zRcAUYHhwA+fc5865gsDkQiCxbssUEZGahBLoHYCtQdOZgXnVuR2YXdUCM7vTzNLMLC0rKyv0KkVEpEZ1+qWomd0MpALPVLXcOTfBOZfqnEtt1apVXW5aROS0FxFCm21Ax6DpxMC8w5jZ5cCjwMXOuUN1U56IiIQqlDP0RUBXM0s2s8bASGB6cAMz6wv8HRjmnNtd92WKiEhNagx051wJcA/wEbAaeMs5t9LMnjSzYYFmzwCxwNtmtszMplezOhEROUFC6XLBOTcLmFVp3uNBty+v47pEROQYhRToJ0txcTGZmZkUFhbWdynSQERFRZGYmEijRo3quxSRBq9BBXpmZiZNmzYlKSkJM6vvcqSeOefIzs4mMzOT5OTk+i5HpMFrUGO5FBYWkpCQoDAXAMyMhIQEfWITCVGDCnRAYS6H0fNBJHQNLtBFRKR2FOhBsrOz6dOnD3369KFt27Z06NChYrqoqOio901LS+O+++6rcRsDBw6sq3JFRA7ToL4UrW8JCQksW7YMgPHjxxMbG8tDDz1UsbykpISIiKofstTUVFJTU2vcxvz58+uk1pOptLSU8PDw+i5DRGrQYAN93DgIZGud6dMHnnvu2O4zevRooqKiWLp0KYMGDWLkyJHcf//9FBYW0qRJE1577TW6d+/O3LlzefbZZ5kxYwbjx49ny5YtbNy4kS1btjBu3LiKs/fY2Fjy8/OZO3cu48ePp2XLlqxYsYL+/fvzxhtvYGbMmjWLBx98kJiYGAYNGsTGjRuZMWPGYXVt3ryZW265hQMHDgDwt7/9reLs/+mnn+aNN94gLCyMoUOH8l//9V9kZGRw1113kZWVRXh4OG+//TZbt26tqBngnnvuITU1ldGjR5OUlMSNN97IJ598wsMPP8z+/fuZMGECRUVFnHHGGUyePJno6Gh27drFXXfdxcaNGwF4+eWX+fDDD4mPj2fcuHEAPProo7Ru3Zr777+/dgdORELSYAO9IcnMzGT+/PmEh4eTl5fHl19+SUREBHPmzOG3v/0t//73v4+4z5o1a/j888/Zv38/3bt3Z+zYsUdcS7106VJWrlxJ+/btGTRoEF999RWpqan8/Oc/Z968eSQnJzNq1Kgqa2rdujWffPIJUVFRrF+/nlGjRpGWlsbs2bN5//33+frrr4mOjmbv3r0A3HTTTTzyyCNce+21FBYWUlZWxtatW6tcd7mEhASWLFkCeN1Rd9xxBwCPPfYYr776Kvfeey/33XcfF198Me+99x6lpaXk5+fTvn17rrvuOsaNG0dZWRlTpkzhm2++OebHXUSOTYMN9GM9kz6Rbrjhhoouh9zcXG677TbWr1+PmVFcXFzlfa6++moiIyOJjIykdevW7Nq1i8TEw4eJHzBgQMW8Pn36sHnzZmJjY/nBD35Qcd31qFGjmDBhwhHrLy4u5p577mHZsmWEh4ezbt06AObMmcNPf/pToqOjAYiPj2f//v1s27aNa6+9FvB+rBOKG2+8seL2ihUreOyxx9i3bx/5+fn88Ic/BOCzzz5j0qRJAISHhxMXF0dcXBwJCQksXbqUXbt20bdvXxISEkLapojUXoMN9IYkJiam4vbvfvc7LrnkEt577z02b97M4MGDq7xPZGRkxe3w8HBKSkpq1aY6f/nLX2jTpg3p6emUlZWFHNLBIiIiKCsrq5iufL138H6PHj2aadOmkZKSwsSJE5k7d+5R1/2zn/2MiRMnsnPnTsaMGXPMtYnIsdNVLscoNzeXDh28/99j4sSJdb7+7t27s3HjRjZv3gzA1KlTq62jXbt2hIWFMXnyZEpLSwG44ooreO211ygo8P4Dqb1799K0aVMSExOZNm0aAIcOHaKgoIDOnTuzatUqDh06xL59+/j000+rrWv//v20a9eO4uJi3nzzzYr5l112GS+//DLgfXmam5sLwLXXXsuHH37IokWLKs7mReTEUqAfo4cffpjf/OY39O3b95jOqEPVpEkTXnrpJYYMGUL//v1p2rQpcXFxR7T7xS9+weuvv05KSgpr1qypOJseMmQIw4YNIzU1lT59+vDss88CMHnyZF544QV69+7NwIED2blzJx07dmTEiBH07NmTESNG0Ldv32rreuqppzj33HMZNGgQZ555ZsX8559/ns8//5xevXrRv39/Vq1aBUDjxo255JJLGDFihK6QETlJzDlXLxtOTU11aWlph81bvXo1Z511Vr3U05Dk5+cTGxuLc467776brl278sADD9R3WcekrKyMfv368fbbb9O1a9fjWpeeFyLfM7PFzrkqr5HWGXoD9Morr9CnTx/OPvtscnNz+fnPf17fJR2TVatWccYZZ3DZZZcdd5iLSOj0pWgD9MADD5xyZ+TBevToUXFduoicPDpDFxHxCQW6iIhPKNBFRHxCgS4i4hMK9CCXXHIJH3300WHznnvuOcaOHVvtfQYPHkz55ZdXXXUV+/btO6LN+PHjK64Hr860adMqruEGePzxx5kzZ84xVC8ipzsFepBRo0YxZcqUw+ZNmTKl2gGyKps1axbNmzev1bYrB/qTTz7J5ZdfXqt11ZfyX6uKSP1ouIE+bhwMHly3f4HhXKtz/fXXM3PmzIr/zGLz5s1s376dCy+8kLFjx5KamsrZZ5/NE088UeX9k5KS2LNnDwB/+MMf6NatGxdccAFr166taPPKK69wzjnnkJKSwo9//GMKCgqYP38+06dP51e/+hV9+vRhw4YNjB49mnfeeQeATz/9lL59+9KrVy/GjBnDoUOHKrb3xBNP0K9fP3r16sWaNWuOqGnz5s1ceOGF9OvXj379+h02HvvTTz9Nr169SElJ4ZFHHgEgIyODyy+/nJSUFPr168eGDRuYO3cu11xzTcX97rnnnophD5KSkvj1r39d8SOiqvYPYNeuXVx77bWkpKSQkpLC/Pnzefzxx3kuaBS2Rx99lOeff/6ox0hEqtdwA70exMfHM2DAAGbPng14Z+cjRozAzPjDH/5AWloay5cv54svvmD58uXVrmfx4sVMmTKFZcuWMWvWLBYtWlSx7LrrrmPRokWkp6dz1lln8eqrrzJw4ECGDRvGM888w7Jly+jSpUtF+8LCQkaPHs3UqVP59ttvKSkpqRg7BaBly5YsWbKEsWPHVtmtUz7M7pIlS5g6dWrFuOzBw+ymp6fz8MMPA94wu3fffTfp6enMnz+fdu3a1fi4lQ+zO3LkyCr3D6gYZjc9PZ0lS5Zw9tlnM2bMmIqRGsuH2b355ptr3J6IVK3h/rConsbPLe92GT58OFOmTKkIpLfeeosJEyZQUlLCjh07WLVqFb17965yHV9++SXXXnttxRC2w4YNq1hW3TC01Vm7di3Jycl069YNgNtuu40XX3yx4j+PuO666wDo378/77777hH31zC7IqePhhvo9WT48OE88MADLFmyhIKCAvr378+mTZt49tlnWbRoES1atGD06NFHDDUbqmMdhrYm5UPwVjf8robZFTl9qMulktjYWC655BLGjBlT8WVoXl4eMTExxMXFsWvXrooumepcdNFFTJs2jYMHD7J//34++OCDimXVDUPbtGlT9u/ff8S6unfvzubNm8nIyAC8URMvvvjikPdHw+yKnD4U6FUYNWoU6enpFYGekpJC3759OfPMM/nJT37CoEGDjnr/fv36ceONN5KSksLQoUM555xzKpZVNwztyJEjeeaZZ+jbty8bNmyomB8VFcVrr73GDTfcQK9evQgLC+Ouu+4KeV80zK7I6UPD50q9CmWYXT0vRL6n4XOlQdIwuyJ1S1+KSr3RMLsidavBnaHXVxeQNEx6PoiErkEFelRUFNnZ2XoRC+CFeXZ2dq0utRQ5HTWoLpfExEQyMzPJysqq71KkgYiKiiIxMbG+yxA5JTSoQG/UqBHJycn1XYaIyCkppC4XMxtiZmvNLMPMHqlieaSZTQ0s/9rMkuq8UhEROaoaA93MwoEXgaFAD2CUmfWo1Ox2IMc5dwbwF+Dpui5URESOLpQz9AFAhnNuo3OuCJgCDK/UZjjweuD2O8BlZmZ1V6aIiNQklD70DsDWoOlM4Nzq2jjnSswsF0gA9gQ3MrM7gTsDk/lmtpbQtay8vtPE6bjfp+M+w+m536fjPsPx7Xfn6hac1C9FnXMTgAm1ua+ZpVX3c1c/Ox33+3TcZzg99/t03Gc4cfsdSpfLNqBj0HRiYF6VbcwsAogDsuuiQBERCU0ogb4I6GpmyWbWGBgJTK/UZjpwW+D29cBnTr8OEhE5qWrscgn0id8DfASEA/90zq00syeBNOfcdOBVYLKZZQB78UK/rtWqq8YHTsf9Ph33GU7P/T4d9xlO0H7X2/C5IiJStxrUWC4iIlJ7CnQREZ84JQK9pqEH/MDMOprZ52a2ysxWmtn9gfnxZvaJma0P/Nuivmuta2YWbmZLzWxGYDo5MIRERmBIicb1XWNdM7PmZvaOma0xs9Vmdv5pcqwfCDy/V5jZv8wsym/H28z+aWa7zWxF0Lwqj615Xgjs+3Iz63c8227wgR7i0AN+UAL80jnXAzgPuDuwn48AnzrnugKfBqb95n5gddD008BfAkNJ5OANLeE3zwMfOufOBFLw9t/Xx9rMOgD3AanOuZ54F1mMxH/HeyIwpNK86o7tUKBr4O9O4OXj2XCDD3RCG3rglOec2+GcWxK4vR/vBd6Bw4dVeB34Ub0UeIKYWSJwNfCPwLQBl+INIQH+3Oc44CK8q8NwzhU55/bh82MdEAE0CfxeJRrYgc+Ot3NuHt7VfsGqO7bDgUnOsxBobmbtarvtUyHQqxp6oEM91XJSBEar7At8DbRxzu0ILNoJtKmvuk6Q54CHgbLAdAKwzzlXEpj24/FOBrKA1wJdTf8wsxh8fqydc9uAZ4EteEGeCyzG/8cbqj+2dZpvp0Kgn1bMLBb4NzDOOZcXvCzwYy3fXGdqZtcAu51zi+u7lpMsAugHvOyc6wscoFL3it+ONUCg33g43htaeyCGI7smfO9EHttTIdBDGXrAF8ysEV6Yv+mcezcwe1f5R7DAv7vrq74TYBAwzMw243WlXYrXt9w88JEc/Hm8M4FM59zXgel38ALez8ca4HJgk3MuyzlXDLyL9xzw+/GG6o9tnebbqRDooQw9cMoL9B2/Cqx2zv05aFHwsAq3Ae+f7NpOFOfcb5xzic65JLzj+plz7ibgc7whJMBn+wzgnNsJbDWz7oFZlwGr8PGxDtgCnGdm0YHne/l++/p4B1R3bKcDtwaudjkPyA3qmjl2zrkG/wdcBawDNgCP1nc9J2gfL8D7GLYcWBb4uwqvT/lTYD0wB4iv71pP0P4PBmYEbv8A+AbIAN4GIuu7vhOwv32AtMDxnga0OB2ONfAfwBpgBTAZiPTb8Qb+hfcdQTHep7Hbqzu2gOFdxbcB+BbvCqBab1s//RcR8YlToctFRERCoEAXEfEJBbqIiE8o0EVEfEKBLiLiEwp0ERGfUKCLiPjE/weKogZ3aA547gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train processing plot\n",
    "epochs=range(1,n_epochs+1)\n",
    "plt.ylim(0,1.0)\n",
    "plt.plot(epochs,Accuracytrain,'b',label='Training accuracy')  \n",
    "plt.plot(epochs, Accuracyvalid,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "torch.save(model,\"SelfResnet18_400.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_test:  3803.0\n",
      "n_test:  4119\n",
      "Loss: 7.747, Accuracy: 0.923\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "losses_test = []\n",
    "n_test = 0\n",
    "acc_test = 0\n",
    "model.eval()\n",
    "\n",
    "for x, t in dataloader_test:\n",
    "    n_test += t.size()[0]\n",
    "    x = x.to(device)  # テンソルをGPUに移動\n",
    "    t = t.to(device)\n",
    "    y = model.forward(x)  # 順伝播\n",
    "    loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "    pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "    acc_test += (pred == t).float().sum().item()\n",
    "    losses_test.append(loss.tolist())\n",
    "\n",
    "# Visualize loss & accuracy \n",
    "print(\"acc_test: \", acc_test) \n",
    "print(\"n_test: \", n_test)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(np.mean(losses_test),acc_test/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"SelfResnet18_300.pkl\")\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(512, 2)\n",
    "# )\n",
    "\n",
    "#Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "loss_func = nn.NLLLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 0.148, Accuracy: 0.960], Valid [Loss: 0.100, Accuracy: 0.963]\n",
      "EPOCH: 1, Train [Loss: 0.127, Accuracy: 0.955], Valid [Loss: 0.110, Accuracy: 0.963]\n",
      "EPOCH: 2, Train [Loss: 0.127, Accuracy: 0.958], Valid [Loss: 0.489, Accuracy: 0.954]\n",
      "EPOCH: 3, Train [Loss: 0.140, Accuracy: 0.955], Valid [Loss: 0.101, Accuracy: 0.971]\n",
      "EPOCH: 4, Train [Loss: 0.127, Accuracy: 0.955], Valid [Loss: 0.101, Accuracy: 0.959]\n",
      "EPOCH: 5, Train [Loss: 0.128, Accuracy: 0.959], Valid [Loss: 0.101, Accuracy: 0.963]\n",
      "EPOCH: 6, Train [Loss: 0.121, Accuracy: 0.962], Valid [Loss: 0.099, Accuracy: 0.964]\n",
      "EPOCH: 7, Train [Loss: 0.124, Accuracy: 0.961], Valid [Loss: 0.098, Accuracy: 0.965]\n",
      "EPOCH: 8, Train [Loss: 0.126, Accuracy: 0.957], Valid [Loss: 0.097, Accuracy: 0.969]\n",
      "EPOCH: 9, Train [Loss: 0.120, Accuracy: 0.960], Valid [Loss: 0.099, Accuracy: 0.964]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "# negative : ラベル0の数\n",
    "# positive : ラベル1の数\n",
    "# weight_for_0 : 1. / negative * (negative + positive)\n",
    "# weight_for_1 : 1. / positive * (negative + positive)\n",
    "# class_weight = {0 : weight_for_0, 1 : weight_for_1}\n",
    "weights = torch.tensor([(len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_01), \n",
    "                        (len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_02Nami)]).cuda()\n",
    "loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # 定义优化器\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99) # 定义衰减策略\n",
    "\n",
    "device = \"cuda\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model)\n",
    "# model.to(device)\n",
    "\n",
    "losstrain=[]\n",
    "lossvalid=[]\n",
    "Accuracytrain=[]\n",
    "Accuracyvalid=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    # Train\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    scheduler.step()\n",
    "    # Visualize loss & accuracy    \n",
    "    losstrain.append(np.mean(losses_train))   \n",
    "    Accuracytrain.append(acc_train/n_train)\n",
    "    lossvalid.append(np.mean(losses_train))\n",
    "    Accuracyvalid.append(acc_val/n_val)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(epoch,np.mean(losses_train),acc_train/n_train,np.mean(losses_valid),acc_val/n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_test:  3790.0\n",
      "n_test:  4119\n",
      "Loss: 0.499, Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "losses_test = []\n",
    "n_test = 0\n",
    "acc_test = 0\n",
    "model.eval()\n",
    "\n",
    "for x, t in dataloader_test:\n",
    "    n_test += t.size()[0]\n",
    "    x = x.to(device)  # テンソルをGPUに移動\n",
    "    t = t.to(device)\n",
    "    y = model.forward(x)  # 順伝播\n",
    "    loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "    pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "    acc_test += (pred == t).float().sum().item()\n",
    "    losses_test.append(loss.tolist())\n",
    "\n",
    "# Visualize loss & accuracy \n",
    "print(\"acc_test: \", acc_test) \n",
    "print(\"n_test: \", n_test)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(np.mean(losses_test),acc_test/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "torch.save(model,\"SelfResnet18_310.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

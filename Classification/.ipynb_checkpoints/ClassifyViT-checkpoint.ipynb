{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,precision_score,accuracy_score,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from vit_pytorch import ViT\n",
    "from vit_pytorch.mobile_vit import MobileViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.device(cuda)\n",
      "torch.cuda.device_count():  1\n",
      "Tesla V100-SXM2-16GB\n",
      "torch.cuda.current_device() 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"torch.device(cuda)\")\n",
    "    print(\"torch.cuda.device_count(): \", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name())\n",
    "    print(\"torch.cuda.current_device()\", torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"torch.device(cpu)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untreaded_train.shape: (3000, 100, 100, 3)\n",
      "VPAtreaded_train.shape: (3000, 100, 100, 3)\n",
      "untreaded_test.shape: (210, 100, 100, 3)\n",
      "VPAtreaded_test.shape: (210, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data(x)\n",
    "untreaded_train=np.load(\"results2022/untreaded_train.npy\",allow_pickle=True)\n",
    "# untreaded_train=np.load(\"results2022/untreaded_train_all.npy\",allow_pickle=True)[:10000]\n",
    "VPAtreaded_train=np.load(\"results2022/VPAtreaded_train.npy\",allow_pickle=True)\n",
    "untreaded_test=np.load(\"results2022/untreaded_test.npy\",allow_pickle=True)\n",
    "VPAtreaded_test=np.load(\"results2022/VPAtreaded_test.npy\",allow_pickle=True)\n",
    "\n",
    "print(\"untreaded_train.shape:\", untreaded_train.shape)\n",
    "print(\"VPAtreaded_train.shape:\", VPAtreaded_train.shape)\n",
    "print(\"untreaded_test.shape:\", untreaded_test.shape)\n",
    "print(\"VPAtreaded_test.shape:\", VPAtreaded_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label(y)\n",
    "y_untreaded_train = np.zeros(len(untreaded_train), dtype=np.int32)\n",
    "y_VPAtreaded_train = np.ones(len(VPAtreaded_train), dtype=np.int32)\n",
    "\n",
    "y_untreaded_test = np.zeros(len(untreaded_test), dtype=np.int32)\n",
    "y_VPAtreaded_test = np.ones(len(VPAtreaded_test), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate x and y\n",
    "X_train, X_test = np.concatenate((untreaded_train, VPAtreaded_train), axis = 0), np.concatenate((untreaded_test, VPAtreaded_test), axis = 0)\n",
    "y_train, y_test = np.concatenate((y_untreaded_train, y_VPAtreaded_train), axis = 0), np.concatenate((y_untreaded_test, y_VPAtreaded_test), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class cell_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x[idx]), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "# trainval_data = cell_dataset(X_train, y_train)\n",
    "train_data = cell_dataset(X_train, y_train)\n",
    "val_data = cell_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1627023533467,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "xK5exWXUDNKn"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# val_size = int(len(trainval_data)*0.2)\n",
    "# train_size = len(trainval_data) - val_size\n",
    "\n",
    "# train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "dataloader_train = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train :  6000\n",
      "train_class_0:  3000\n",
      "train_class_1:  3000\n",
      "\n",
      "Total number of val :  420\n",
      "val_class_0:  210\n",
      "val_class_1:  210\n",
      "\n",
      "Total number of test :  420\n",
      "test_class_0 num :  210\n",
      "test_class_1 num :  210\n"
     ]
    }
   ],
   "source": [
    "train_data_01 = 0\n",
    "train_size = len(train_data)\n",
    "for i in range(train_size):\n",
    "    train_data_01+=train_data[i][1].item()\n",
    "print(\"Total number of train : \", train_size)\n",
    "print(\"train_class_0: \", train_size-train_data_01)\n",
    "print(\"train_class_1: \", train_data_01)\n",
    "\n",
    "val_data_01 = 0\n",
    "val_size = len(val_data)\n",
    "for i in range(val_size):\n",
    "    val_data_01+=val_data[i][1].item()\n",
    "print(\"\\nTotal number of val : \", val_size)\n",
    "print(\"val_class_0: \", val_size-val_data_01)\n",
    "print(\"val_class_1: \", val_data_01)\n",
    "\n",
    "test_00 = y_test.tolist().count(0)\n",
    "test_01 = y_test.tolist().count(1)\n",
    "print(\"\\nTotal number of test : \", len(y_test))\n",
    "print(\"test_class_0 num : \", test_00)\n",
    "print(\"test_class_1 num : \", test_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# 3. Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VIwIc2BXDNKp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    image_size = 100,\n",
    "    patch_size = 10,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 1,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ").to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "# #Freeze model weights\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "# negative : ラベル0の数\n",
    "# positive : ラベル1の数\n",
    "# weight_for_0 : 1. / negative * (negative + positive)\n",
    "# weight_for_1 : 1. / positive * (negative + positive)\n",
    "# class_weight = {0 : weight_for_0, 1 : weight_for_1}\n",
    "weights = torch.tensor([(len(untreaded_train)+len(VPAtreaded_train))/len(untreaded_train), \n",
    "                        (len(untreaded_train)+len(VPAtreaded_train))/len(VPAtreaded_train)]).cuda()\n",
    "loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # 定义优化器\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99) # 定义衰减策略\n",
    "\n",
    "\n",
    "# model = model.cuda()\n",
    "model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "losstrain=[]\n",
    "lossvalid=[]\n",
    "Accuracytrain=[]\n",
    "Accuracyvalid=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 7.361, Accuracy: 0.496], Valid [Loss: 0.721, Accuracy: 0.500]\n",
      "EPOCH: 1, Train [Loss: 0.715, Accuracy: 0.504], Valid [Loss: 0.712, Accuracy: 0.500]\n",
      "EPOCH: 2, Train [Loss: 0.729, Accuracy: 0.502], Valid [Loss: 0.698, Accuracy: 0.500]\n",
      "EPOCH: 3, Train [Loss: 0.726, Accuracy: 0.502], Valid [Loss: 0.912, Accuracy: 0.500]\n",
      "EPOCH: 4, Train [Loss: 0.740, Accuracy: 0.510], Valid [Loss: 0.798, Accuracy: 0.500]\n",
      "EPOCH: 5, Train [Loss: 0.735, Accuracy: 0.492], Valid [Loss: 0.701, Accuracy: 0.500]\n",
      "EPOCH: 6, Train [Loss: 0.764, Accuracy: 0.489], Valid [Loss: 0.758, Accuracy: 0.500]\n",
      "EPOCH: 7, Train [Loss: 0.752, Accuracy: 0.502], Valid [Loss: 0.689, Accuracy: 0.500]\n",
      "EPOCH: 8, Train [Loss: 0.737, Accuracy: 0.506], Valid [Loss: 0.675, Accuracy: 0.579]\n",
      "EPOCH: 9, Train [Loss: 0.800, Accuracy: 0.506], Valid [Loss: 0.696, Accuracy: 0.500]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    # Train\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, y in dataloader_train:\n",
    "        n_train += y.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        pred = output.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_train += (pred == y).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        pred = output.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_val += (pred == y).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    scheduler.step()\n",
    "    # Visualize loss & accuracy    \n",
    "    losstrain.append(np.mean(losses_train))\n",
    "    Accuracytrain.append(acc_train/n_train)\n",
    "    lossvalid.append(np.mean(losses_valid))\n",
    "    Accuracyvalid.append(acc_val/n_val)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'\n",
    "          .format(epoch,np.mean(losses_train),acc_train/n_train,np.mean(losses_valid),acc_val/n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train processing plot\n",
    "n_epochs = 100\n",
    "epochs=range(1,n_epochs+1)\n",
    "plt.ylim(0,1.0)\n",
    "plt.plot(epochs,Accuracytrain,'b',label='Training accuracy')  \n",
    "plt.plot(epochs, Accuracyvalid,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X = X_test\n",
    "y = y_test\n",
    "y_pred = []\n",
    "out_pred = []\n",
    "total = X.shape[0]\n",
    "\n",
    "model.eval()\n",
    "for n in range(total):\n",
    "    img = X[n]\n",
    "    label = y[n]\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    output = model(input_tensor)\n",
    "    pred = output.argmax(1).cpu().item()\n",
    "    out_pred.append(output[0][1].item())\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "out_pred = np.array(out_pred)\n",
    "print(\"total_test: {:}\" .format(total))\n",
    "print('accuracy_score: {:.3f}'.format(accuracy_score(y,y_pred)))\n",
    "print('precision_score: {:.3f}'.format(precision_score(y,y_pred)))\n",
    "print('roc_auc_score: {:.3f}'.format(roc_auc_score(y, out_pred)))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, out_pred,drop_intermediate=True)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('FPR: False positive rate')\n",
    "plt.ylabel('TPR: True positive rate')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "torch.save(model,\"SelfResnet18_L2F1_250.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

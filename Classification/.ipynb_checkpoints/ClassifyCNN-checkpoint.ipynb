{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの分布\n",
    "\n",
    "## >> Cells With Mask\n",
    "* NDAcquisition-01：45,723\n",
    "* NDAcquisition-01x40：130,092\n",
    "* NDAcquisition-02Nami_x20：9,096\n",
    "* NDAcquisition-02Nami_x40：4,236\n",
    "\n",
    "## >> Cells No Mask\n",
    "* NDAcquisition-01：45,870\n",
    "* NDAcquisition-01x40：130,147\n",
    "* NDAcquisition-02Nami_x20：9,321\n",
    "* NDAcquisition-02Nami_x40：4,236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max_shape_0 , Max_shape_1\n",
    "\n",
    "\n",
    "### >> Cells \n",
    "\n",
    "    * 01x20\n",
    "        * Max_shape_0:  234\n",
    "        * Max_shape_1:  214\n",
    "\n",
    "    * 02Namix20\n",
    "        * Max_shape_0:  254\n",
    "        * Max_shape_1:  234\n",
    "\n",
    "    * 01x40\n",
    "        * Max_shape_0:  464\n",
    "        * Max_shape_1:  499\n",
    "\n",
    "    * 02Namix40\n",
    "        * Max_shape_0:  354\n",
    "        * Max_shape_1:  274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_01.shape: (11990,)\n",
      "Data_02Nami.shape: (1738,)\n"
     ]
    }
   ],
   "source": [
    "Data_02Nami=np.load(\"data/imread_02Namix40.npy\",allow_pickle=True)\n",
    "Data_01=np.load(\"data/imread_01x40.npy\",allow_pickle=True)\n",
    "print(\"Data_01.shape:\", Data_01.shape)\n",
    "print(\"Data_02Nami.shape:\", Data_02Nami.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_01.shape: (11990,)\n",
      "Data_02Nami.shape: (1738,)\n"
     ]
    }
   ],
   "source": [
    "Data_01=Data_01\n",
    "Data_02Nami=Data_02Nami\n",
    "\n",
    "print(\"Data_01.shape:\", Data_01.shape)\n",
    "print(\"Data_02Nami.shape:\", Data_02Nami.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Padding Unify the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_shape_0 = 100\n",
    "Max_shape_1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPad_01:  11990\n",
      "DataPad_02Nami:  1738\n"
     ]
    }
   ],
   "source": [
    "#　同じサイズにする \n",
    "def datapadding(data):\n",
    "    DataPad=[]\n",
    "    for img in data:\n",
    "        imgSize = img.shape\n",
    "        top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2\n",
    "        left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2\n",
    "        if (imgSize[0] % 2) != 0:\n",
    "            top_size,bottom_size = (Max_shape_0-imgSize[0])//2,(Max_shape_0-imgSize[0])//2+1\n",
    "        if (imgSize[1] % 2) != 0:     \n",
    "            left_size,right_size = (Max_shape_1-imgSize[1])//2,(Max_shape_1-imgSize[1])//2+1\n",
    "        img_pad = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "        DataPad.append(img_pad)\n",
    "    return DataPad\n",
    "\n",
    "DataPad_01 = datapadding(Data_01)\n",
    "DataPad_02Nami = datapadding(Data_02Nami)\n",
    "print(\"DataPad_01: \",len(DataPad_01))\n",
    "print(\"DataPad_02Nami: \",len(DataPad_02Nami))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resize by using Bin_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBinResize = []\n",
    "# def bin_ndarray(ndarray, new_shape, operation):\n",
    "#     operation = operation.lower()\n",
    "#     if not operation in ['sum', 'mean']:\n",
    "#         raise ValueError(\"Operation not supported.\")\n",
    "#     if ndarray.ndim != len(new_shape):\n",
    "#         raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n",
    "#                                                            new_shape))\n",
    "#     compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n",
    "#                                                   ndarray.shape)]\n",
    "#     flattened = [l for p in compression_pairs for l in p]\n",
    "#     ndarray = ndarray.reshape(flattened)\n",
    "#     for i in range(len(new_shape)):\n",
    "#         op = getattr(ndarray, operation)\n",
    "#         ndarray = op(-1*(i+1))\n",
    "#     return ndarray\n",
    "\n",
    "# for img in DataResize:\n",
    "#     imgresize = bin_ndarray(img, new_shape=(512,512,3), operation='mean')\n",
    "#     DataBinResize.append(imgresize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBinResize = np.array(DataBinResize)\n",
    "# print(\"DataBinResize: \", DataBinResize.shape)\n",
    "\n",
    "# img = cv2.imread(DataPath[1])\n",
    "# print(\"DataPath[1].shape: \", img.shape)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DataResize[1].shape: \", DataResize[1].shape)\n",
    "# plt.imshow(DataResize[1])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DataBinResize[1].shape: \", DataBinResize[1].shape)\n",
    "# plt.imshow(DataBinResize[1]/255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPad_01 = DataPad_01\n",
    "DataLabel_01 = np.zeros(len(DataPad_01), dtype=np.int32)\n",
    "\n",
    "DataPad_02Nami = DataPad_02Nami\n",
    "DataLabel_02Nami = np.ones(len(DataPad_02Nami), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train :  9609\n",
      "train_class_0 num :  8393\n",
      "train_class_1 num :  1216\n",
      "\n",
      "Total number of test :  4119\n",
      "test_class_0 num :  3597\n",
      "test_class_1 num :  522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(DataPad_01, DataLabel_01,\n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(DataPad_02Nami, DataLabel_02Nami,\n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_test = np.concatenate((X_train_0, X_train_1), axis = 0), np.concatenate((X_test_0, X_test_1), axis = 0)\n",
    "y_train, y_test = np.concatenate((y_train_0, y_train_1), axis = 0), np.concatenate((y_test_0, y_test_1), axis = 0)\n",
    "\n",
    "print(\"Total number of train : \", len(y_train))\n",
    "print(\"train_class_0 num : \", y_train.tolist().count(0))\n",
    "print(\"train_class_1 num : \", y_train.tolist().count(1))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Total number of test : \", len(y_test))\n",
    "print(\"test_class_0 num : \", y_test.tolist().count(0))\n",
    "print(\"test_class_1 num : \", y_test.tolist().count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4277,
     "status": "ok",
     "timestamp": 1627022925074,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "gijcrKa5DNKm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu102'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class train_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        data = x_train.astype('float32')\n",
    "        self.x_train = []\n",
    "        for i in range(data.shape[0]):\n",
    "            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
    "        self.y_train = y_train\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x_train[idx]), torch.tensor(y_train[idx], dtype=torch.long)\n",
    "\n",
    "    \n",
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_test, y_test):\n",
    "        data = x_test.astype('float32')\n",
    "        self.x_test = []\n",
    "        for i in range(data.shape[0]):\n",
    "            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n",
    "        self.y_test = y_test\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x_test[idx]), torch.tensor(y_test[idx], dtype=torch.long)\n",
    "\n",
    "trainval_data = train_dataset(X_train, y_train)\n",
    "test_data = test_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1627023533467,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "xK5exWXUDNKn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  7688\n",
      "val_size:  1921\n",
      "test_size:  4119\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "val_size = int(len(trainval_data)*0.2)\n",
    "train_size = len(trainval_data) - val_size\n",
    "print(\"train_size: \",train_size)\n",
    "print(\"val_size: \",val_size)\n",
    "print(\"test_size: \",len(y_test))\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# ResNet遷移学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VIwIc2BXDNKp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "xs6IXgvsDNKp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True)\n",
    "# num_fcs = model.fc.in_features\n",
    "# # FC層のクラス数を変更\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(num_fcs, 512),\n",
    "#     # nn.Dropout(p=0.5),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(256, 2)\n",
    "# )\n",
    "\n",
    "model = torch.load(\"SelfResnet18_300.pkl\")\n",
    "\n",
    "#Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "loss_func = nn.NLLLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 0.119, Accuracy: 0.947], Valid [Loss: 0.529, Accuracy: 0.917]\n",
      "EPOCH: 1, Train [Loss: 0.131, Accuracy: 0.949], Valid [Loss: 0.419, Accuracy: 0.893]\n",
      "EPOCH: 2, Train [Loss: 0.282, Accuracy: 0.875], Valid [Loss: 0.294, Accuracy: 0.894]\n",
      "EPOCH: 3, Train [Loss: 0.321, Accuracy: 0.849], Valid [Loss: 0.296, Accuracy: 0.857]\n",
      "EPOCH: 4, Train [Loss: 0.191, Accuracy: 0.923], Valid [Loss: 0.298, Accuracy: 0.891]\n",
      "EPOCH: 5, Train [Loss: 0.208, Accuracy: 0.901], Valid [Loss: 0.328, Accuracy: 0.894]\n",
      "EPOCH: 6, Train [Loss: 0.242, Accuracy: 0.887], Valid [Loss: 0.266, Accuracy: 0.871]\n",
      "EPOCH: 7, Train [Loss: 0.136, Accuracy: 0.940], Valid [Loss: 0.313, Accuracy: 0.864]\n",
      "EPOCH: 8, Train [Loss: 0.113, Accuracy: 0.950], Valid [Loss: 0.489, Accuracy: 0.920]\n",
      "EPOCH: 9, Train [Loss: 0.272, Accuracy: 0.947], Valid [Loss: 0.432, Accuracy: 0.868]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "# negative : ラベル0の数\n",
    "# positive : ラベル1の数\n",
    "# weight_for_0 : 1. / negative * (negative + positive)\n",
    "# weight_for_1 : 1. / positive * (negative + positive)\n",
    "# class_weight = {0 : weight_for_0, 1 : weight_for_1}\n",
    "weights = torch.tensor([(len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_01), \n",
    "                        (len(DataPad_01)+len(DataPad_02Nami))/len(DataPad_02Nami)]).cuda()\n",
    "loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # 定义优化器\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99) # 定义衰减策略\n",
    "\n",
    "device = \"cuda\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model)\n",
    "# model.to(device)\n",
    "\n",
    "losstrain=[]\n",
    "lossvalid=[]\n",
    "Accuracytrain=[]\n",
    "Accuracyvalid=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    # Train\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "        y = model.forward(x)  # 順伝播\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    scheduler.step()\n",
    "    # Visualize loss & accuracy    \n",
    "    losstrain.append(np.mean(losses_train))   \n",
    "    Accuracytrain.append(acc_train/n_train)\n",
    "    lossvalid.append(np.mean(losses_train))\n",
    "    Accuracyvalid.append(acc_val/n_val)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(epoch,np.mean(losses_train),acc_train/n_train,np.mean(losses_valid),acc_val/n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train processing plot\n",
    "epochs=range(1,n_epochs+1)\n",
    "plt.ylim(0,1.0)\n",
    "plt.plot(epochs,Accuracytrain,'b',label='Training accuracy')  \n",
    "plt.plot(epochs, Accuracyvalid,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model,\"SelfResnet18_400.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_test:  3816.0\n",
      "n_test:  4119\n",
      "Loss: 1.006, Accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "losses_test = []\n",
    "n_test = 0\n",
    "acc_test = 0\n",
    "model.eval()\n",
    "\n",
    "for x, t in dataloader_test:\n",
    "    n_test += t.size()[0]\n",
    "    x = x.to(device)  # テンソルをGPUに移動\n",
    "    t = t.to(device)\n",
    "    y = model.forward(x)  # 順伝播\n",
    "    loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "    pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "    acc_test += (pred == t).float().sum().item()\n",
    "    losses_test.append(loss.tolist())\n",
    "\n",
    "# Visualize loss & accuracy \n",
    "print(\"acc_test: \", acc_test) \n",
    "print(\"n_test: \", n_test)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(np.mean(losses_test),acc_test/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
